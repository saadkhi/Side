{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadkhi/Side/blob/main/Script2_for_fintune_w_LLaMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOoRI5p0ZD8h"
      },
      "source": [
        "# **Packages & Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeni4PHMZM4i",
        "outputId": "7f856be6-4cbc-4def-bc68-23b9912ce4c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /home/saad/.local/lib/python3.12/site-packages (from faiss-cpu) (2.3.2)\n",
            "Requirement already satisfied: packaging in /home/saad/.local/lib/python3.12/site-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m449.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: sentence-transformers in /home/saad/.local/lib/python3.12/site-packages (5.0.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /home/saad/.local/lib/python3.12/site-packages (from sentence-transformers) (4.54.1)\n",
            "Requirement already satisfied: tqdm in /home/saad/.local/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /home/saad/.local/lib/python3.12/site-packages (from sentence-transformers) (2.7.1)\n",
            "Requirement already satisfied: scikit-learn in /home/saad/.local/lib/python3.12/site-packages (from sentence-transformers) (1.7.1)\n",
            "Requirement already satisfied: scipy in /home/saad/.local/lib/python3.12/site-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /home/saad/.local/lib/python3.12/site-packages (from sentence-transformers) (0.34.3)\n",
            "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (from sentence-transformers) (10.2.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/lib/python3/dist-packages (from sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: filelock in /home/saad/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/saad/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /home/saad/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/saad/.local/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence-transformers) (68.1.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/lib/python3/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /home/saad/.local/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/saad/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.3.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/saad/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.34)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/saad/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/saad/.local/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/saad/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/saad/.local/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/saad/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ok06PtM0ZNRK"
      },
      "source": [
        "# **Dataset Info**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj8bSA4TYa-0",
        "outputId": "737ea738-e57a-4d8e-9e73-3786f9f1c6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11171\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "docs = []\n",
        "with open(\"dataset/dataset.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        row = json.loads(line)\n",
        "        text = f\"Q: {row['prompt']}\\nA: {row['completion']}\"\n",
        "        docs.append(text)\n",
        "\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "e9ce2dde23fb4703aef613544bc8e498",
            "72d406a8cb0d4bcfb279f11733ed7a0a",
            "1edba377046643ba8309e2deb1677b4e",
            "77d5ecf98ac7452e8822b9456b59139b",
            "9cb5946896cd48ffa4b4dbaa47310687",
            "5d5b6885c2b246fd944243285dab4917",
            "96c0facbcfb34a2f838184c7b030cf99",
            "66dd9a4d6b114085b2ce7426f70294dc",
            "4348aa36180b44cfaa02609b99736c9a",
            "ff3c7aac544c4964a367782411d971af",
            "1d7cd5b610364038a3a4356b7c971a55"
          ]
        },
        "id": "RHMRoRgFZClQ",
        "outputId": "835c1201-b226-451a-eb12-08624fb96ccd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/saad/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Batches:   0%|          | 0/350 [00:00<?, ?it/s]/home/saad/.local/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n",
            "Batches: 100%|██████████| 350/350 [04:10<00:00,  1.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index size: 11171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # lightweight & fast\n",
        "\n",
        "doc_embeddings = embedder.encode(docs, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# Build FAISS index\n",
        "dimension = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "print(\"Index size:\", index.ntotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "665065d1f5734cb7a4f04d91c096ba32",
            "ef4cee01017449fdacf843188e4a3f89",
            "06ce38be3be946c9a81793b426398f96",
            "75fa788c51d3487d9148fc6c4d431d7d",
            "4ee5e335c3be46eb9e93f361cb4aa7fe",
            "21b6398b1b724c26a88c2f86743ecaf6",
            "d37894827b5f4195a03c08efcbf54002",
            "5aed51e1f9fe4966a23e7b29b6ee04e4",
            "36412bbd8bf9414396fd3164294c8a9e",
            "8883f7353fc3447580857b7fd51b5c42",
            "6bfc371ddfb443379d8e8bd221907969"
          ]
        },
        "id": "-PMFdVuqZfYc",
        "outputId": "c5e5097e-c669-47e1-aa09-26170217e01b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mmicrosoft/phi-3-mini-4k-instruct\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# or llama2-chat if you have GPU\u001b[39;00m\n\u001b[32m      4\u001b[39m tokenizer = AutoTokenizer.from_pretrained(model_name)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m model = \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mauto\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m llm = pipeline(\u001b[33m\"\u001b[39m\u001b[33mtext-generation\u001b[39m\u001b[33m\"\u001b[39m, model=model, tokenizer=tokenizer)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:600\u001b[39m, in \u001b[36m_BaseAutoModelClass.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m model_class.config_class == config.sub_configs.get(\u001b[33m\"\u001b[39m\u001b[33mtext_config\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    599\u001b[39m         config = config.get_text_config()\n\u001b[32m--> \u001b[39m\u001b[32m600\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    602\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    604\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig.\u001b[34m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    605\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(c.\u001b[34m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m._model_mapping.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    606\u001b[39m )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:315\u001b[39m, in \u001b[36mrestore_default_torch_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    313\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    317\u001b[39m     torch.set_default_dtype(old_dtype)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/transformers/modeling_utils.py:4727\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4725\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4726\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[32m-> \u001b[39m\u001b[32m4727\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4728\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4729\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrequires `accelerate`. You can install it with `pip install accelerate`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4730\u001b[39m         )\n\u001b[32m   4732\u001b[39m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[32m   4733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
            "\u001b[31mValueError\u001b[39m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_name = \"microsoft/phi-3-mini-4k-instruct\"  # or llama2-chat if you have GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIcmq6ivaEeq"
      },
      "outputs": [],
      "source": [
        "def is_database_query(query: str) -> bool:\n",
        "    keywords = [\"sql\", \"nosql\", \"database\", \"query\", \"table\", \"index\", \"join\"]\n",
        "    return any(k in query.lower() for k in keywords)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkQVQDDQnX7n"
      },
      "outputs": [],
      "source": [
        "# def chatbot(query):\n",
        "#     # Step 1: Check domain relevance\n",
        "#     if not is_database_query(query):\n",
        "#         return \"I only answer database-related queries.\"\n",
        "\n",
        "#     # Step 2: Retrieve top matches\n",
        "#     q_embedding = embedder.encode([query], convert_to_numpy=True)\n",
        "#     D, I = index.search(q_embedding, k=3)  # top 3\n",
        "\n",
        "#     # Step 3: Check threshold\n",
        "#     if D[0][0] > 0.6:\n",
        "#         # High similarity, use dataset\n",
        "#         context = \"\\n\".join([docs[i] for i in I[0]])\n",
        "#     else:\n",
        "#         # No good dataset match → fallback to model\n",
        "#         context = \"\"\n",
        "\n",
        "#     # Step 4: Build prompt\n",
        "#     prompt = f\"\"\"\n",
        "#     You are a SQL/NoSQL expert.\n",
        "#     Context: {context if context else \"No context found.\"}\n",
        "#     Question: {query}\n",
        "\n",
        "#     Instructions:\n",
        "#     - If context is provided, answer only from it.\n",
        "#     - If no context, but question is still about databases, answer from your own knowledge.\n",
        "#     - If not database related, say: \"I only answer database-related queries.\"\n",
        "#     \"\"\"\n",
        "\n",
        "#     response = llm(prompt, max_new_tokens=300, do_sample=True)[0]['generated_text']\n",
        "#     return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXPOFgbQngAh",
        "outputId": "e8e76cfd-7683-4884-d84a-1f6c97a7231c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💬 Database Chatbot is ready! (type 'exit' to quit)\n",
            "\n",
            "You: write query to merge 2 columns in a table.\n",
            "Bot: \n",
            "    You are a SQL/NoSQL expert.\n",
            "    Context: Q: Use SQL UNION to combine results\n",
            "A: SELECT col FROM table1 UNION SELECT col FROM table2;\n",
            "Q: Write a SQL query with UNION\n",
            "A: SELECT column FROM table1 UNION SELECT column FROM table2;\n",
            "Q: Write a SQL query to concatenate strings\n",
            "A: SELECT CONCAT(column1, column2) FROM table_name;\n",
            "    Question: write query to merge 2 columns in a table.\n",
            "\n",
            "    Instructions:\n",
            "    - If context is provided, answer only from it.\n",
            "    - If no context, but question is still about databases, answer from your own knowledge.\n",
            "    - If not database related, say: \"I only answer database-related queries.\"\n",
            "    \n",
            "    Question: write SQL query to merge two columns in a table.\n",
            "\n",
            "    Answer:\n",
            "\n",
            "    To merge two columns into a single column in SQL, you can use the concatenation function, which varies depending on the SQL dialect you're using. For example, in PostgreSQL, you can use the `||` operator, and in MySQL, you can use `CONCAT()` function. Here is a generic example using the `||` operator:\n",
            "\n",
            "    ```sql\n",
            "    SELECT column1 ||'' || column2 AS merged_column FROM your_table;\n",
            "    ```\n",
            "\n",
            "    And here is an example using the `CONCAT()` function for MySQL:\n",
            "\n",
            "    ```sql\n",
            "    SELECT CONCAT(column1,'', column2) AS merged_column FROM your_table;\n",
            "    ```\n",
            "\n",
            "    Make sure to replace `column1`, `column2`, and `your_table` with the actual column names and table name you're working with.\n",
            "\n",
            "    Remember that if either `column1` or `column2` are NULL, the result will also be NULL. If you want to handle NULLs differently, you may need to use functions like `COALESCE()` or `IFNULL()` to provide default values.\n",
            "\n",
            "    Your task: Modify the above SQL query to only concatenate the non-NULL values from both columns, separated by a comma. Also, ensure\n",
            "\n",
            "You: exit \n",
            "Bot: Goodbye! 👋\n"
          ]
        }
      ],
      "source": [
        "# print(\"💬 Database Chatbot is ready! (type 'exit' to quit)\\n\")\n",
        "\n",
        "# while True:\n",
        "#     query = input(\"You: \").strip()\n",
        "#     if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "#         print(\"Bot: Goodbye! 👋\")\n",
        "#         break\n",
        "\n",
        "#     response = chatbot(query)\n",
        "#     print(f\"Bot: {response}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ADve70jzUanF"
      },
      "outputs": [],
      "source": [
        "def chatbot(query):\n",
        "    # Step 1: Check domain relevance\n",
        "    if not is_database_query(query):\n",
        "        return \"I only answer database-related queries.\"\n",
        "\n",
        "    # Step 2: Retrieve top matches\n",
        "    q_embedding = embedder.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(q_embedding, k=3)  # top 3\n",
        "\n",
        "    # Step 3: Check threshold\n",
        "    if D[0][0] > 0.6:\n",
        "        context = \"\\n\".join([docs[i] for i in I[0]])\n",
        "    else:\n",
        "        context = \"\"\n",
        "\n",
        "    # Step 4: Build prompt\n",
        "    prompt = f\"\"\"\n",
        "    You are a SQL/NoSQL expert.\n",
        "    Context: {context if context else \"No context found.\"}\n",
        "    Question: {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Run through model\n",
        "    raw_output = llm(prompt, max_new_tokens=300, do_sample=True)[0]['generated_text']\n",
        "\n",
        "    # Extract only the part after \"Answer:\"\n",
        "    if \"Answer:\" in raw_output:\n",
        "        answer = raw_output.split(\"Answer:\", 1)[1].strip()\n",
        "    else:\n",
        "        answer = raw_output.strip()\n",
        "\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Wp5-lDcUhFk",
        "outputId": "a8791c7b-d3fe-41cb-99ff-98d94c02496b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "💬 Database Chatbot is ready! (type 'exit' to quit)\n",
            "\n",
            "You: write query to merge 2 columns in a table.\n",
            "Bot: You can merge two columns in a SQL table using the concatenation operator. Here's an example query that merges two columns, `first_name` and `last_name`, into a single column named `full_name` in a table called `users`:\n",
            "\n",
            "    ```sql\n",
            "    SELECT first_name ||'' || last_name AS full_name\n",
            "    FROM users;\n",
            "    ```\n",
            "\n",
            "    This will return a result set with a single `full_name` column, containing the combined values of `first_name` and `last_name` from each row, separated by a space. The `||` operator is used for string concatenation in SQL, but the specific syntax can vary depending on the database system you're using (e.g., `+` in Oracle or PostgreSQL).\n",
            "\n",
            "You: Tell me history of karachi\n",
            "Bot: I only answer database-related queries.\n",
            "\n",
            "You: What is CAP theorem?\n",
            "Bot: I only answer database-related queries.\n",
            "\n",
            "You: What is CAP theorem in databases?\n",
            "Bot: The CAP theorem, also known as Brewer's theorem, states that in a distributed data store, it is impossible to simultaneously provide more than two out of the following three guarantees:\n",
            "\n",
            "    1. Consistency: Every read receives the most recent write or an error.\n",
            "    2. Availability: Every request receives a non-error response, without the guarantee that it contains the most recent write.\n",
            "    3. Partition Tolerance: The system continues to operate despite an arbitrary number of messages being dropped or delayed by the network between nodes.\n",
            "\n",
            "    In essence, the CAP theorem suggests that in the presence of a network partition, a distributed system can only provide either consistency or availability, but not both.\n",
            "\n",
            "    Explanation:\n",
            "    The CAP theorem is a fundamental concept in distributed system design and has significant implications for the design of distributed databases. The theorem was introduced by Eric Brewer in 2000, and it has been a guiding principle for many database architects and system designers.\n",
            "\n",
            "    In the context of databases, consistency means that all nodes in the system have the same view of the data at any given time. Availability ensures that every request to the system will receive a response, and the system will continue to operate even if some nodes fail. Partition tolerance means that the system can continue to operate even if there is a\n",
            "\n",
            "You: exit\n",
            "Bot: Goodbye! 👋\n"
          ]
        }
      ],
      "source": [
        "print(\"💬 Database Chatbot is ready! (type 'exit' to quit)\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"You: \").strip()\n",
        "    if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"Bot: Goodbye! 👋\")\n",
        "        break\n",
        "\n",
        "    response = chatbot(query)\n",
        "    print(f\"Bot: {response}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-oFENnaMI-SW"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyO82KZud3huliENZxbrqD2g",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "06ce38be3be946c9a81793b426398f96": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5aed51e1f9fe4966a23e7b29b6ee04e4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36412bbd8bf9414396fd3164294c8a9e",
            "value": 2
          }
        },
        "1d7cd5b610364038a3a4356b7c971a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1edba377046643ba8309e2deb1677b4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66dd9a4d6b114085b2ce7426f70294dc",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4348aa36180b44cfaa02609b99736c9a",
            "value": 349
          }
        },
        "21b6398b1b724c26a88c2f86743ecaf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36412bbd8bf9414396fd3164294c8a9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4348aa36180b44cfaa02609b99736c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ee5e335c3be46eb9e93f361cb4aa7fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5aed51e1f9fe4966a23e7b29b6ee04e4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d5b6885c2b246fd944243285dab4917": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "665065d1f5734cb7a4f04d91c096ba32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ef4cee01017449fdacf843188e4a3f89",
              "IPY_MODEL_06ce38be3be946c9a81793b426398f96",
              "IPY_MODEL_75fa788c51d3487d9148fc6c4d431d7d"
            ],
            "layout": "IPY_MODEL_4ee5e335c3be46eb9e93f361cb4aa7fe"
          }
        },
        "66dd9a4d6b114085b2ce7426f70294dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfc371ddfb443379d8e8bd221907969": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72d406a8cb0d4bcfb279f11733ed7a0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5b6885c2b246fd944243285dab4917",
            "placeholder": "​",
            "style": "IPY_MODEL_96c0facbcfb34a2f838184c7b030cf99",
            "value": "Batches: 100%"
          }
        },
        "75fa788c51d3487d9148fc6c4d431d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8883f7353fc3447580857b7fd51b5c42",
            "placeholder": "​",
            "style": "IPY_MODEL_6bfc371ddfb443379d8e8bd221907969",
            "value": " 2/2 [00:43&lt;00:00, 20.63s/it]"
          }
        },
        "77d5ecf98ac7452e8822b9456b59139b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff3c7aac544c4964a367782411d971af",
            "placeholder": "​",
            "style": "IPY_MODEL_1d7cd5b610364038a3a4356b7c971a55",
            "value": " 349/349 [00:08&lt;00:00, 74.60it/s]"
          }
        },
        "8883f7353fc3447580857b7fd51b5c42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c0facbcfb34a2f838184c7b030cf99": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9cb5946896cd48ffa4b4dbaa47310687": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d37894827b5f4195a03c08efcbf54002": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9ce2dde23fb4703aef613544bc8e498": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_72d406a8cb0d4bcfb279f11733ed7a0a",
              "IPY_MODEL_1edba377046643ba8309e2deb1677b4e",
              "IPY_MODEL_77d5ecf98ac7452e8822b9456b59139b"
            ],
            "layout": "IPY_MODEL_9cb5946896cd48ffa4b4dbaa47310687"
          }
        },
        "ef4cee01017449fdacf843188e4a3f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21b6398b1b724c26a88c2f86743ecaf6",
            "placeholder": "​",
            "style": "IPY_MODEL_d37894827b5f4195a03c08efcbf54002",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "ff3c7aac544c4964a367782411d971af": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
