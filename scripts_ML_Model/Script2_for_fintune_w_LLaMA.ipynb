{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN/I6axnI76+kaIRtt3wATl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saadkhi/Side/blob/main/scripts_ML_Model/Script2_for_fintune_w_LLaMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Packages & Libraries**"
      ],
      "metadata": {
        "id": "oOoRI5p0ZD8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu\n",
        "!pip install sentence-transformers"
      ],
      "metadata": {
        "id": "oeni4PHMZM4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Info and finrtuning**"
      ],
      "metadata": {
        "id": "Ok06PtM0ZNRK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bj8bSA4TYa-0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "docs = []\n",
        "with open(\"dataset.jsonl\", \"r\") as f:\n",
        "    for line in f:\n",
        "        row = json.loads(line)\n",
        "        text = f\"Q: {row['prompt']}\\nA: {row['completion']}\"\n",
        "        docs.append(text)\n",
        "\n",
        "print(len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # lightweight & fast\n",
        "\n",
        "doc_embeddings = embedder.encode(docs, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "# Build FAISS index\n",
        "dimension = doc_embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(doc_embeddings)\n",
        "\n",
        "print(\"Index size:\", index.ntotal)"
      ],
      "metadata": {
        "id": "RHMRoRgFZClQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "model_name = \"microsoft/phi-3-mini-4k-instruct\"  # or llama2-chat if you have GPU\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "\n",
        "llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "-PMFdVuqZfYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_database_query(query: str) -> bool:\n",
        "    keywords = [\"SQL\",\"NoSQL\",\"Database\",\"Query\",\"Table\",\"Collection\",\"Document\",\"Key-Value\",\"Graph\",\"Schema\",\"Index\",\"Primary Key\",\"Foreign Key\",\"Join\",\"INNER JOIN\",\"LEFT JOIN\",\"RIGHT JOIN\",\"FULL JOIN\",\"SELECT\",\"INSERT\",\"UPDATE\",\"DELETE\",\"WHERE\",\"GROUP BY\",\"HAVING\",\"ORDER BY\",\"LIMIT\",\"OFFSET\",\"DISTINCT\",\"COUNT\",\"SUM\",\"AVG\",\"MAX\",\"MIN\",\"Aggregation\",\"Subquery\",\"CTE\",\"View\",\"Trigger\",\"Stored Procedure\",\"Transaction\",\"ACID\",\"BASE\",\"Normalization\",\"Denormalization\",\"Partitioning\",\"Sharding\",\"Replication\",\"Consistency\",\"Eventual Consistency\",\"Index Scan\",\"Full Scan\",\"Constraint\",\"UNIQUE\",\"NOT NULL\",\"CHECK\",\"MongoDB\",\"Redis\",\"Neo4j\",\"Cassandra\",\"DynamoDB\",\"find\",\"aggregate\",\"$match\",\"$group\",\"$sort\",\"$limit\",\"$skip\",\"$project\",\"$lookup\",\"$unwind\",\"$push\",\"$pull\",\"$set\",\"$unset\",\"SET\",\"GET\",\"LPUSH\",\"RPOP\",\"SADD\",\"ZADD\",\"HSET\",\"HGET\",\"Node\",\"Relationship\",\"MATCH\",\"CREATE\",\"MERGE\",\"Cypher\",\"Index Maintenance\",\"Query Optimization\",\"Execution Plan\",\"EXPLAIN\",\"Materialized View\",\"Caching\",\"TTL\",\"Full-Text Search\",\"Data Modeling\",\"Connection Pooling\",\"Deadlock\",\"ALTER\",\"DROP\",\"TRUNCATE\",\"CREATE TABLE\",\"CREATE INDEX\",\"CREATE VIEW\",\"COMMIT\",\"ROLLBACK\",\"SAVEPOINT\",\"LOCK\",\"UNLOCK\",\"ANALYZE\",\"VACUUM\",\"CLUSTER\",\"REINDEX\",\"CHECKPOINT\",\"CASCADE\",\"RESTRICT\",\"DEFAULT\",\"GENERATED ALWAYS\",\"SEQUENCE\",\"CURSOR\",\"FETCH\",\"OVER\",\"PARTITION BY\",\"RANK\",\"DENSE_RANK\",\"ROW_NUMBER\",\"NTILE\",\"LAG\",\"LEAD\",\"FIRST_VALUE\",\"LAST_VALUE\",\"PERCENTILE_CONT\",\"PERCENTILE_DISC\",\"WITHIN GROUP\",\"LIKE\",\"ILIKE\",\"SIMILAR TO\",\"REGEXP\",\"COALESCE\",\"NULLIF\",\"CASE\",\"UNION ALL\",\"INTERSECT\",\"EXCEPT\",\"CROSS JOIN\",\"NATURAL JOIN\",\"SELF JOIN\",\"MERGE INTO\",\"UPSERT\",\"EXISTS\",\"NOT EXISTS\",\"ANY\",\"ALL\",\"IN\",\"NOT IN\",\"BETWEEN\",\"CAST\",\"CONVERT\",\"CURRENT_DATE\",\"CURRENT_TIMESTAMP\",\"DATEADD\",\"DATEDIFF\",\"EXTRACT\",\"TO_CHAR\",\"TO_DATE\",\"JSON\",\"JSONB\",\"TSVECTOR\",\"TSQUERY\",\"$geoNear\",\"$geoWithin\",\"$elemMatch\",\"$size\",\"$exists\",\"$type\",\"$regex\",\"$in\",\"$nin\",\"$or\",\"$and\",\"$not\",\"$avg\",\"$sum\",\"$min\",\"$max\",\"HDEL\",\"HINCRBY\",\"LINDEX\",\"LLEN\",\"RPUSH\",\"LPOP\",\"SISMEMBER\",\"SDIFF\",\"SUNION\",\"SINTER\",\"ZSCORE\",\"ZCOUNT\",\"RETURN\",\"DETACH DELETE\",\"OPTIONAL MATCH\",\"UNWIND\",\"CALL\",\"YIELD\",\"Backup\",\"Failover\",\"Read Replica\",\"Write-Ahead Logging\",\"Hot Standby\",\"Cold Backup\",\"Snapshot Isolation\",\"Query Cache\",\"Multi-Tenancy\",\"Data Integrity\",\"Index Fragmentation\",\"Query Timeout\",\"Connection Timeout\",\"Read Consistency\",\"Write Conflict\"]\n",
        "    return any(k in query.lower() for k in keywords)"
      ],
      "metadata": {
        "id": "SIcmq6ivaEeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(query):\n",
        "    # Step 1: Check domain relevance\n",
        "    if not is_database_query(query):\n",
        "        return \"I only answer database-related queries.\"\n",
        "\n",
        "    # Step 2: Retrieve top matches\n",
        "    q_embedding = embedder.encode([query], convert_to_numpy=True)\n",
        "    D, I = index.search(q_embedding, k=3)  # top 3\n",
        "\n",
        "    # Step 3: Check threshold\n",
        "    if D[0][0] > 0.6:\n",
        "        context = \"\\n\".join([docs[i] for i in I[0]])\n",
        "    else:\n",
        "        context = \"\"\n",
        "\n",
        "    # Step 4: Build prompt\n",
        "    prompt = f\"\"\"\n",
        "    You are a SQL/NoSQL expert.\n",
        "    Context: {context if context else \"No context found.\"}\n",
        "    Question: {query}\n",
        "\n",
        "    Answer:\n",
        "    \"\"\"\n",
        "\n",
        "    # Run through model\n",
        "    raw_output = llm(prompt, max_new_tokens=300, do_sample=True)[0]['generated_text']\n",
        "\n",
        "    # Extract only the part after \"Answer:\"\n",
        "    if \"Answer:\" in raw_output:\n",
        "        answer = raw_output.split(\"Answer:\", 1)[1].strip()\n",
        "    else:\n",
        "        answer = raw_output.strip()\n",
        "\n",
        "    return answer\n"
      ],
      "metadata": {
        "id": "ADve70jzUanF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ’¬ Database Chatbot is ready! (type 'exit' to quit)\\n\")\n",
        "\n",
        "while True:\n",
        "    query = input(\"You: \").strip()\n",
        "    if query.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
        "        print(\"Bot: Goodbye! ðŸ‘‹\")\n",
        "        break\n",
        "\n",
        "    response = chatbot(query)\n",
        "    print(f\"Bot: {response}\\n\")"
      ],
      "metadata": {
        "id": "5Wp5-lDcUhFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObnXAGgX-tEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}